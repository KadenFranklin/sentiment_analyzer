{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d672f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from nltk import sentiment\n",
    "from IPython.display import display, Markdown\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5aca68c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Kaden's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06a641",
   "metadata": {},
   "source": [
    "# Sentiment_Analyzer\n",
    "\n",
    "#### BOTH OTHER FILES STORED IN THIS REPOSITORY WERE USED AS REFERENCE FOR THIS FILES CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409b0fe",
   "metadata": {},
   "source": [
    "We begin by importing the data file and looking at a portion of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d06c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Local Names                   Translation    Location Real Names\n",
      "0      Abombo                            _   Kisanagani     Dupont\n",
      "1       Adami                        Madam       Opala     generic\n",
      "2     Adamisu  Knowing eyes, control, anger      Basoko          _\n",
      "3       Aduyi                          Lion           _          _\n",
      "4       Aginu                      Kneeling   Kisangani      Genot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Names</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Location</th>\n",
       "      <th>Real Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271</td>\n",
       "      <td>270</td>\n",
       "      <td>267</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>270</td>\n",
       "      <td>188</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tuku-Tuku</td>\n",
       "      <td>_</td>\n",
       "      <td>Katanga</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Local Names Translation Location Real Names\n",
       "count          271         270      267        264\n",
       "unique         270         188       91        100\n",
       "top      Tuku-Tuku           _  Katanga          _\n",
       "freq             2          65       26        123"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Kaden's Laptop\\Documents\\GitHub\\KadenFranklin.github.io\\sentiment_analyzer\\names1.csv\")\n",
    "print(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aef221",
   "metadata": {},
   "source": [
    "The data gathered for this analyis is collected from King Leopold's Congo and the \"Scramble for Africa\" by Michael A. Rutz\n",
    "\n",
    "Specifically from page 163 and the 'Sample of names used in this word'.\n",
    "\n",
    "We can see from the commands above that there are 271 rows of names, with 270 unique names, 188 distinct translations, originating from 91 locations. In addition to this, asside from collective 'meta' names there are 99 names given to colonials by natives.\n",
    "\n",
    "The datatypes are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f888835e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Local Names    object\n",
       "Translation    object\n",
       "Location       object\n",
       "Real Names     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b28d6e",
   "metadata": {},
   "source": [
    "Local Name - Object\n",
    "\n",
    "Translation - Object\n",
    "\n",
    "Location - Object\t\n",
    "\n",
    "Real Name - Object\n",
    "\n",
    "Now just to be certain we will check the dataset for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab70d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "for x in data.duplicated():\n",
    "    i += 1\n",
    "    if x == True:\n",
    "        print(x)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc172c",
   "metadata": {},
   "source": [
    "Success, no duplicates, Now we move on to the interesting part, [sentiment analysis](https://monkeylearn.com/sentiment-analysis/).\n",
    "\n",
    "Now we can split our data into its corresponding columns so that we can work with it more easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1308a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1 = list(data[\"Local Names\"])\n",
    "transl = list(data[\"Translation\"])\n",
    "location = list(data[\"Location\"])\n",
    "names_2 = list(data['Real Names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13454b",
   "metadata": {},
   "source": [
    "The function below defines the [markdown](https://www.markdownguide.org/) table, which the results of our analysis will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c488b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown_table(headers: List[str], data: List) -> str:\n",
    "    s = f\"| {' | '.join(headers)} |\\n| {' | '.join([(max(1, len(header) - 1)) * '-' + ':' for header in headers])} |\\n\"\n",
    "    for row in data:\n",
    "        s += f\"| {' | '.join([str(item) for item in row])} |\\n\"\n",
    "    display(Markdown(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d8a0d",
   "metadata": {},
   "source": [
    "The function below takes in an input of either one name, or a list of names. It will return a resulting markdown table giving the scores of such input names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa9063d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_name_analyzer(name):\n",
    "    dis=[]\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    if isinstance(name, list):\n",
    "        dis.append([[sid.polarity_scores(x)] for x in name])\n",
    "        return dis\n",
    "                \n",
    "    else:\n",
    "        return sid.polarity_scores(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b288b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sw_name_analyzer(name):\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()    \n",
    "\n",
    "    return sid.polarity_scores(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af9925",
   "metadata": {},
   "source": [
    "Having defined such functions we can perform an analysis on our own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9188e5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1033291091.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [113]\u001b[1;36m\u001b[0m\n\u001b[1;33m    rows = [[names_1[i += 1], sw_name_analyzer(names), location[i]] for names in names_1]\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#en_name_analyzer(transl)\n",
    "#en_name_analyzer(names_2)\n",
    "i = -1\n",
    "\n",
    "headers = ['local name', 'score', 'location']\n",
    "rows = [[names_1[i], sw_name_analyzer(names), location[i]] for names in names_1]\n",
    "show_markdown_table(headers, rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43a4c5",
   "metadata": {},
   "source": [
    "Now that we have performed the necessary evaluation of our names, lets organize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d14db94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize by region here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be312f",
   "metadata": {},
   "source": [
    "In this file we have used the [Vader](https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664) library to perform Sentiment Analysis on a list of roughly 270 names. Vader allows for the performance of multilingual Sentiment analysis through 3rd party translation APIs. What this means is that inputs from other languages are translated to english in order to calculate a sentiment score. I tried looking for a Natural Language Processing database in Swahili, Kikongo, & Lingala. But resources in computer science are sparse in these langauges.\n",
    "\n",
    "For the reasons above, the words with translated sentiment should be weighted less in the consideration of the word's lasting impact today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a3bca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
