{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "28290319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Kaden's\n",
      "[nltk_data]     Laptop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "40358934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: translate-api in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (4.9.5)\n",
      "Requirement already satisfied: lxml>=4.5.0 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translate-api) (4.9.1)\n",
      "Requirement already satisfied: requests>=2.25.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translate-api) (2.28.1)\n",
      "Requirement already satisfied: pathos>=0.2.7 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translate-api) (0.2.9)\n",
      "Requirement already satisfied: PyExecJS>=1.5.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translate-api) (1.5.1)\n",
      "Requirement already satisfied: loguru>=0.4.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translate-api) (0.6.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from loguru>=0.4.1->translate-api) (0.4.4)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from loguru>=0.4.1->translate-api) (1.1.0)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.7->translate-api) (0.3.5.1)\n",
      "Requirement already satisfied: pox>=0.3.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.7->translate-api) (0.3.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.7->translate-api) (1.7.6.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.7->translate-api) (0.70.13)\n",
      "Requirement already satisfied: six>=1.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ppft>=1.7.6.5->pathos>=0.2.7->translate-api) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.1->translate-api) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.1->translate-api) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.1->translate-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.25.1->translate-api) (2.10)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: translators in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (5.4.2)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translators) (4.9.1)\n",
      "Requirement already satisfied: pathos>=0.2.9 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translators) (0.2.9)\n",
      "Requirement already satisfied: loguru>=0.6.0 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translators) (0.6.0)\n",
      "Requirement already satisfied: requests>=2.28.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translators) (2.28.1)\n",
      "Requirement already satisfied: PyExecJS>=1.5.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from translators) (1.5.1)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from loguru>=0.6.0->translators) (1.1.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from loguru>=0.6.0->translators) (0.4.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.9->translators) (0.70.13)\n",
      "Requirement already satisfied: pox>=0.3.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.9->translators) (0.3.1)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.9->translators) (0.3.5.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from pathos>=0.2.9->translators) (1.7.6.5)\n",
      "Requirement already satisfied: six>=1.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ppft>=1.7.6.5->pathos>=0.2.9->translators) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.28.1->translators) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.28.1->translators) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.28.1->translators) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaden's laptop\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.28.1->translators) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install translate-api\n",
    "!pip install translators --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "97dacd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "855bc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from nltk import sentiment\n",
    "from IPython.display import display, Markdown\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06a641",
   "metadata": {},
   "source": [
    "# Sentiment_Analyzer\n",
    "\n",
    "#### BOTH OTHER FILES STORED IN THIS REPOSITORY WERE USED AS REFERENCE FOR THIS FILES CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29874af3",
   "metadata": {},
   "source": [
    "We begin by importing the data file and looking at a portion of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c406b721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Local Names                   Translation    Location Real Names\n",
      "0      Abombo                             _  Kisanagani     Dupont\n",
      "1       Adami                         Madam      Opala     generic\n",
      "2     Adamisu  Knowing eyes, control, anger      Basoko          _\n",
      "3       Aduyi                          Lion           _          _\n",
      "4       Aginu                      Kneeling   Kisangani      Genot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Names</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Location</th>\n",
       "      <th>Real Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>267</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>270</td>\n",
       "      <td>180</td>\n",
       "      <td>81</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tuku-Tuku</td>\n",
       "      <td>_</td>\n",
       "      <td>Katanga</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Local Names Translation Location Real Names\n",
       "count          271         271      267        271\n",
       "unique         270         180       81         99\n",
       "top      Tuku-Tuku           _  Katanga          _\n",
       "freq             2          68       28        130"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Kaden's Laptop\\Documents\\GitHub\\KadenFranklin.github.io\\sentiment_analyzer\\names1.csv\")\n",
    "print(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aef221",
   "metadata": {},
   "source": [
    "The data gathered for this analyis is collected from King Leopold's Congo and the \"Scramble for Africa\" by Michael A. Rutz\n",
    "\n",
    "Specifically from page 163 and the 'Sample of names used in this word'.\n",
    "\n",
    "We can see from the commands above that there are 271 rows of names, with 270 unique names, 188 distinct translations, originating from 91 locations. In addition to this, asside from collective 'meta' names there are 99 names given to colonials by natives.\n",
    "\n",
    "The datatypes are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9875e7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Local Names    object\n",
       "Translation    object\n",
       "Location       object\n",
       "Real Names     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ad0b7",
   "metadata": {},
   "source": [
    "Local Name - Object\n",
    "\n",
    "Translation - Object\n",
    "\n",
    "Location - Object\t\n",
    "\n",
    "Real Name - Object\n",
    "\n",
    "Now just to be certain we will check the dataset for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ff7796cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "for x in data.duplicated():\n",
    "    i += 1\n",
    "    \n",
    "    if x == True:\n",
    "        print(x)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f06c72",
   "metadata": {},
   "source": [
    "Success, no duplicates, Now we move on to the interesting part, [sentiment analysis](https://monkeylearn.com/sentiment-analysis/).\n",
    "\n",
    "Now we can split our data into its corresponding columns so that we can work with it more easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "50b61e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1 = list(data['Local Names'])\n",
    "transl = list(data[\"Translation\"])\n",
    "location = list(data[\"Location\"])\n",
    "names_2 = list(data['Real Names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bd84f",
   "metadata": {},
   "source": [
    "This piece of code shows any name with punctuation, it will break when encountering nan or null values and was used for error testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d0789440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D'Hondt\n",
      "Cloetens et al.\n",
      "G. Schweinfurth\n",
      "G. Miani\n",
      "P.-J. Van de Moere\n",
      "P.-J. Van de Moere\n",
      "H. Bombeeck\n",
      "L. Oswald, L. Adhémar, C. de Leuze\n",
      "L. Oswald, L. Adhémar, C. de Leuze\n",
      "T.Nicolas\n",
      "G. Dineur\n",
      "F. Van Nimmen, J. Van Uden\n",
      "F. Van Nimmen, J. Van Uden\n",
      "R. Bearts\n",
      "A. Demunster\n",
      "A. Lippens\n",
      "E. Schnitzer (Emin Pacha)\n",
      "E. Schnitzer (Emin Pacha)\n",
      "E. Schnitzer (Emin Pacha)\n",
      "L. De Brandt\n",
      "A.J.G. Bolle\n",
      "J. de Dixmude\n",
      "A.J.G. Bolle\n",
      "G. Junker\n",
      "M. Spelier\n",
      "G.O. Scioz\n",
      "P. Ponthier\n",
      "M. Caetano Pereira\n",
      "P.J. Van de Moere\n",
      "Bell, M. Polis\n",
      "Bell, M. Polis\n",
      "A. De Meulemeester\n",
      "Mayo-Monteiro\n",
      "Bandundu, Bulungu\n",
      "H. Bombeeck \n",
      "M. Caetano Pereira\n",
      "G. Miani\n",
      "G. Miani\n",
      "J.M.F. Tumers\n",
      "G. Geerearts\n",
      "H. Dupuis Shaw\n",
      "J. Fievez\n",
      "J. Fievez\n",
      "J. Fievez\n",
      "G. Casati\n",
      "L. A. Borms\n",
      "J. Fievez\n",
      "J. Fievez\n",
      "C. Van de Laniotte\n",
      "V. Rue\n",
      "N. Tobback\n",
      "L. Van den Brooke\n",
      "L. Van den Brooke\n",
      "J. Vansina\n"
     ]
    }
   ],
   "source": [
    "str_punk = '''!()-[]{};:'\"\\,<>./?@#$%^&*~'''\n",
    "no_p = \"\"\n",
    "\n",
    "for item in names_2:\n",
    "    for el in str_punk:\n",
    "        if el in item:\n",
    "            print(item)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1833d1",
   "metadata": {},
   "source": [
    "The function below defines the [markdown](https://www.markdownguide.org/) table, which the results of our analysis will be stored.\n",
    "\n",
    "As you can see there are also some helper function I've created to help iterate through data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e9f5f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown_table(headers: List[str], data: List) -> str:\n",
    "    s = f\"| {' | '.join(headers)} |\\n| {' | '.join([(max(1, len(header) - 1)) * '-' + ':' for header in headers])} |\\n\"\n",
    "    for row in data:\n",
    "        s += f\"| {' | '.join([str(item) for item in row])} |\\n\"\n",
    "    display(Markdown(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d8a0d",
   "metadata": {},
   "source": [
    "The function below takes in an input of either one name, or a list of names. It will return a resulting markdown table giving the scores of such input names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "aa9063d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_name_analyzer(name):\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()    \n",
    "\n",
    "    return sid.polarity_scores(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "58158346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sw_name_analyzer(name):\n",
    "    \n",
    "    for x, elem in enumerate(name):\n",
    "\n",
    "        name[x] = ts.google(elem)\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()    \n",
    "\n",
    "    return sid.polarity_scores(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ab7d6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #dis=[]\n",
    "    #sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    #if isinstance(name, list):\n",
    "    #    dis.append([[sid.polarity_scores(x)] for x in name])\n",
    "    #    return dis\n",
    "                \n",
    "    #else:\n",
    "    #    return sid.polarity_scores(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abombo', 'Adami', 'Adamisu', 'Aduyi', 'Aginu', 'Agomiriya', 'Alali na se', 'Alinga Mama', 'Alinga Likaya', 'Alinga Tumba', 'Alube', 'Angbalima', 'Angbotalikume', 'Angwadima', 'Asali Monkanda', 'Atama-Atama', 'Atamu', 'Ataso', 'Atila Okondo', 'Awaya-Awaya', 'Bajunu', 'Bakola', 'Bala-Bala', 'Balikpe', 'Balikuhe', 'Bambenga', 'Bana Muanama', 'Bandungu', 'Bapenda Kula', 'Basikoti', 'Batu Pamba', 'Belei', 'Bikengakenga', 'Bola-Bola', 'Bolemba', 'Bombeki', 'Bosolo', 'Bula Matari', 'Bula Matende', 'Bumba', 'Bwana Kapia', 'Bwana Kaseya', 'Bwana Kenengene', 'Bwana Kidogo', 'Bwana Kioseni', 'Bwana Kitoko', 'Bwana Leke', 'Bwana Lubuku', 'Bwana Lutshina', 'Bwana Maibwe', 'Bwana Mukubwa', 'Bwana Mzuri', 'Bwana Ndeke ', 'Bwana Ndeke', 'Bwana Nioka ', 'Bwana Nzige', 'Bwana Pangabisoto ', 'Bwana Tomasi', 'Bwana Tumbaku', 'Chakundia', 'Chicotte', 'Cibalabala', 'Cibutama', 'Cimpanga', 'Ciswa-bantu', 'Citoko', 'Djeke', 'Djoko deli', 'Ebeniq', 'Ebuka-Buka', 'Efanja', 'Ekanda', 'Ekanga-kanga', 'Ekatankoi', 'Ekuma', 'Eminimbi', 'Engalala', 'Etumba Mbilo', 'Ewa-Olefe', 'Fasa ou Nkosa Nkosa', 'Fazzari', 'Fimbo Mingi', 'Genda genda', 'Guruguru', 'Hela', 'Hoy na Gola', 'Iboko', 'Ikeleso', 'Ikoka', 'Ikuka', 'Ilanga', 'Ipanga Ngunda', 'Ipipola', 'Itumba Mbilu', 'Kabalo', 'Kabangu', 'Kabesa Babo', 'Kabuakiatunge', 'Kakese', 'Kamuziki', 'Kangipipe', 'Kapiteni', 'Kaputi', 'Kaseya', 'Kashabala', 'Kasiama Nkoi', 'Kasongo Bushila', 'Kasongo Mule', 'Kelekeke', 'Kelelo', 'Kilupula', 'Kimbwi', 'Kiomba Musinga', 'Kitatshindja', 'Kitoko', 'Kituanga', 'Kobinda', 'Koja', 'Kolongo', 'Koma-Koma', 'Komanda', 'Konga', 'Kulu-Kulu', 'Kuta Bongo', 'Lambo', 'Lamu', 'Liamamba', 'Liboma', 'Libumbu', 'Libumu', 'Likoka', 'Likoke', 'Likwama', 'Lilanga-atumbe', 'Limende', 'Liombo', 'Lipumbu', 'Lokesa', 'Lokonga', 'Lombolembo', 'Longo-Longo', 'Longwango', 'Longwani', 'Loponge', 'Luanda', 'Lubuku', 'Lukwako', 'Lumandemulu', 'Madami', 'Mafuta', 'Mafuta Mingi', 'Maine mingi', 'Maina', 'Makasi', 'Makisi', 'Makpatu', 'Makupkup', 'Malakolo', 'Mala-Mala', 'Malanda', 'Malenge', 'Malonga Longa', 'Malu-Malu', 'Mandevu Mingi', 'Mangbe', 'Mangema', 'Matala-Tala', 'Matamba-Tamba', 'Matcho Kali', 'Matuba', 'Mayala', 'Mbavu Munene', 'Mbavu Nguvu', 'Mfumu Mantese', 'Miere-Miere', 'Miso Minei', 'Miti', 'Moke', 'Moke-Moke', 'Molanda', 'Mondele Madami', 'Mondele Mboka', 'Mondele na Kawa', 'Mondele na Loso', 'Mondele na Mbila', 'Mondele Ngolo', 'Monganga na Mabele', 'Monginda(Bonginda)', 'Mpimbo Mingi', 'Msirkanda', 'Mudiata ou Nyata', 'Mukalenge Leka', 'Mundele Kikufi', 'Mundele Mbisi', 'Mundele Ngolo', 'Mundele Nioka', 'Mundele Nzazi', 'Munyololo', 'Mupe', 'Mupenda Batu', 'Mupenda Kula', 'Muzungu wa Pamba', 'Mwambe', 'Mwana Mputu', 'Mwandami', 'Mwendo-Mwendo', 'Nabira', 'Nafranki', 'Ndeke, Ndeke-Ndeke', 'Ndevu', 'Ndjole-Ndjole', 'Ndoki', 'Ngangabuka', 'Nganga Nzambe', 'Ngolo Mingi', 'Ngona na batu', 'Ngongo Leteta', 'Nialakowomubu', 'Niangeniange', 'Nkake', 'Nkangobeko', 'Nkoso', 'Nkoyi(Nkoi)', 'Nsoni Mingi', 'Ntange', 'Nyimi-Nyimi', 'Nyoka', 'Nzoku', 'Nzokumasi', \"Ondele W'Ekonge\", 'Padiri', 'Paipo', 'Pamba', 'Panzi', 'Pebe', 'Pete ya Mai ya Sombe', 'Pole-Pole', 'Rumaliza', 'Sango', 'Sato', 'Sesa', 'Sikitele', 'Sikoti', 'Simba Bulaya', 'Singa', 'Situka', 'Sokele(Lokele)', 'Soso Aleli', 'Soso Mombi', 'Soso Mpembe', 'Sukuma', 'Tange', 'Tata', 'Tomansangu', 'Tomilali', 'Tomo', 'Toro', 'Tshienda Bitekete', 'Tshiwayawaya', 'Tshoma-Tshoma', 'Tshombe Bululu', 'Tuku-Tuku', 'Tuku-Tuku', 'Tumbaku', 'Tumba Lombe', 'Tumpa Mokono', 'Vandebunduki', 'Vandenbuluki', 'Vansina', 'Wai-Wai', 'Yamba-Yamba'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(names_1, '\\n')\n",
    "print(sw_name_analyzer(names_1))\n",
    "\n",
    "# should put some other print statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d31171",
   "metadata": {},
   "source": [
    "Having defined such functions we can perform an analysis on our own dataset.\n",
    "\n",
    "The code below is complex, but I will annotate it to the best of my ability.\n",
    " \n",
    " comments are denoted with '#' marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['local name', 'score', 'location', 'translation', 'real name']\n",
    "# This line denotes the first line of output data, our heading\n",
    "\n",
    "rows = [[names_1[num], sw_name_analyzer(names), location[num], \n",
    "         str(transl[num] + \" \" + str(en_name_analyzer(trnl)['compound'])), \n",
    "         str(names_2[num] + \" \" + str(en_name_analyzer(name_2)['compound']))] \n",
    "        for num, (names, name_2, trnl) in enumerate(zip(names_1, names_2, transl))]\n",
    "# This section of code defines the rows that will be generated.\n",
    "# It relies on various other functions and lists define above, but this is the most critical section.\n",
    "\n",
    "# 1st line - local names, local name scores, and location lists\n",
    "# 2nd line - Translation list\n",
    "# 3rd line - Real names / origin list\n",
    "# last line - for #, (variables) in enumerate(three different lists)\n",
    "\n",
    "\n",
    "show_markdown_table(headers, rows)\n",
    "# This function combines the two lines above to compile output\n",
    "\n",
    "# can also do # sw_name_analyzer(names)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feac1178",
   "metadata": {},
   "source": [
    "Now that we have performed the necessary evaluation of our names, lets organize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14db94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize by region here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d317b9a",
   "metadata": {},
   "source": [
    "In this file we have used the [Vader](https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664) library to perform Sentiment Analysis on a list of roughly 270 names. Vader allows for the performance of multilingual Sentiment analysis through 3rd party translation APIs. What this means is that inputs from other languages are translated to english in order to calculate a sentiment score. I tried looking for a Natural Language Processing database in Swahili, Kikongo, & Lingala. But resources in computer science are sparse in these langauges.\n",
    "\n",
    "For the reasons above, the words with translated sentiment should be weighted less in the consideration of the word's lasting impact today."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
